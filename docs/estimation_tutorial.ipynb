{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation Tutorial\n",
    "\n",
    "In this section, we dive into the topic of model estimation using **pydsge**. \n",
    "\n",
    "Let us, just for the sake of this tutorial, set up a temporary directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the tutorial: Setting up example structure\n",
    "import tempfile\n",
    "import os\n",
    "import shutil # For clean-up of temporary directory\n",
    "from pathlib import Path # For Windows/Unix compatibility\n",
    "\n",
    "# Temporary output folder\n",
    "output_path = Path(tempfile.gettempdir(), 'output')\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and loading the model\n",
    "\n",
    "Let us first load the relevant packages. Besides the DSGE class we already know from [*getting started*](https://pydsge.readthedocs.io/en/latest/getting_started.html), we also want to import the `emcee` package. This will allow us to later specify the desired updating algorithms for sampling from the posterior distribution - we explain this in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emcee # For specifying updating moves\n",
    "\n",
    "from pydsge import DSGE, example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we continue to use the example provided in `pydsge`. Like before, we specify the file paths of the model and the data. Please feel free to check-out both files, but from the previous tutorial you might remember that we're dealing with a five equations New Keynesian model and US quarterly data from 1995 to 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file, data_file = example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again parse the model and load the data. Importantly we also specify a location where the output is stored. \n",
    "\n",
    "For this tutoral I assign a tempfile as the output path, but this is certainly not what you want. So better change that path. Note also that we can give the model estimation a name and also write a short description, which is very useful when working with several models or estimations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the model\n",
    "mod = DSGE.read(yaml_file)  \n",
    "\n",
    "# Give it a name\n",
    "mod.name = 'rank_tutorial'\n",
    "mod.description = 'RANK, estimation tutorial'\n",
    "\n",
    "# Storage location for output. CHANGE THIS to some local path on your PC!\n",
    "mod.path = output_path\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_file, parse_dates=['date'], index_col=['date'])\n",
    "df.index.freq = 'Q' # let pandas know that this is quartely data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that since the Great Recession, the Federal Funds Rate has been below the ZLB. That is why, like in [*getting started*](https://pydsge.readthedocs.io/en/latest/getting_started.html), we adjust the observed interest rate, so that the data is \"within reach\" of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>Infl</th>\n",
       "      <th>FFR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-03-31</th>\n",
       "      <td>0.77834</td>\n",
       "      <td>0.14386</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-30</th>\n",
       "      <td>0.69635</td>\n",
       "      <td>0.22873</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-09-30</th>\n",
       "      <td>1.03077</td>\n",
       "      <td>0.36109</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-12-31</th>\n",
       "      <td>1.37921</td>\n",
       "      <td>0.26145</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.54307</td>\n",
       "      <td>0.37393</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>0.41475</td>\n",
       "      <td>0.49969</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>0.54594</td>\n",
       "      <td>0.25245</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>0.54391</td>\n",
       "      <td>0.51972</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>0.48458</td>\n",
       "      <td>0.57830</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.48097</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP     Infl   FFR\n",
       "date                              \n",
       "1998-03-31  0.77834  0.14386  1.38\n",
       "1998-06-30  0.69635  0.22873  1.38\n",
       "1998-09-30  1.03077  0.36109  1.38\n",
       "1998-12-31  1.37921  0.26145  1.22\n",
       "1999-03-31  0.54307  0.37393  1.18\n",
       "...             ...      ...   ...\n",
       "2017-03-31  0.41475  0.49969  0.18\n",
       "2017-06-30  0.54594  0.25245  0.24\n",
       "2017-09-30  0.54391  0.51972  0.29\n",
       "2017-12-31  0.48458  0.57830  0.30\n",
       "2018-03-31  0.15170  0.48097  0.36\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust elb\n",
    "zlb = mod.get_par('elb_level')\n",
    "rate = df['FFR']\n",
    "df['FFR'] = np.maximum(rate,zlb)\n",
    "\n",
    "mod.load_data(df, start='1998Q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the packages and loading the data, we still need to tell pydsge how to carry out the estimation of our model. The \"prep_estim\" method can be used to accomplish this. It can be called without any arguments and sets-up a non-linear model by default. However, not all defaults are always a good good choice, and to showcase some of this functionality, we decide to specify several arguments here.\n",
    "\n",
    "To perform the estimation, `pydsge` uses a Transposed-Ensemble Kalman Filter (TEnKF). For general information on its implementation, see the [EconSieve documentation](https://econsieve.readthedocs.io/en/latest/) , and for more details on running the filter in `pydsge` check-out the [*getting started tutorial*](https://pydsge.readthedocs.io/en/latest/getting_started.html). Again,  the default filter is non-linear, but we can opt for a linear one by setting the argument `linear` to `True`. To choose a custom number of ensemble members for the TEnKF, set `N` to a particular number (default is 300, for e.g. a medium scale model 400-500 is a good choice). We can also set a specific random seed with the argument `seed` (the default seed is `0`). To get additional information on the estimation process, we can set  `verbose` to `True`. Conveniently, this information includes an overview of the parameters’ distribution, their means and standard deviations. Finally, if we already specified the covariance matrix of the measurement errors or want to reuse a previous result, we can load it into the `prep_estim` method by setting `Load.R` to `True`. \n",
    "\n",
    "If you run into problems you can turn parallelization off by setting `debug=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[estimation:]   Model operational. 12 states, 3 observables, 3 shocks, 81 data points.\n",
      "Adding parameters to the prior distribution...\n",
      "   - theta as beta (0.5, 0.1). Init @ 0.7813, with bounds (0.2, 0.95)\n",
      "   - sigma as normal (1.5, 0.375). Init @ 1.2312, with bounds (0.25, 3)\n",
      "   - phi_pi as normal (1.5, 0.25). Init @ 1.7985, with bounds (1.0, 3)\n",
      "   - phi_y as normal (0.125, 0.05). Init @ 0.0893, with bounds (0.001, 0.5)\n",
      "   - rho_u as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)\n",
      "   - rho_r as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)\n",
      "   - rho_z as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)\n",
      "   - rho as beta (0.75, 0.1). Init @ 0.8, with bounds (0.5, 0.975)\n",
      "   - sig_u as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.025, 5)\n",
      "   - sig_r as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.01, 3)\n",
      "   - sig_z as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.01, 3)\n",
      "[estimation:]   11 priors detected. Adding parameters to the prior distribution.\n"
     ]
    }
   ],
   "source": [
    "mod.prep_estim(N=350, seed=0, verbose=True, use_prior_transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You probably want to set `use_prior_transform` to `True`, as above. This activates the destinction between prior and sampling space for the [ADEMC sampler](https://gregorboehl.com/live/ademc_boehl.pdf), which reduces the number of neccessary MCMC draws *a lot*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the filtering tutorial, we set the covariance of measurement errors to correspond to the variances of the data. Additionally, we adjust the measurement errors of the Federal Funds rate since it is perfectly observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.filter.R = mod.create_obs_cov(1e-1)\n",
    "ind = mod.observables.index('FFR')\n",
    "mod.filter.R[ind,ind] /= 1e1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets turn to the actual estimation. For a variety of pretty good reasons, `pdygse` uses *Ensemble Markov Chain Monte Carlo* (Ensemble-MCMC) integration to sample from the posterior distribution. For further information on Ensemble-MCMC, please refer to the `emcee` [website](https://emcee.readthedocs.io/en/stable/) and the additional resources provided there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first require an initial ensemble, which is provided by `tmcmc`. `tmcmc` is a very sophisticated function with many options, but right now, all we are interested in is to obtain a sample that represents the prior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:06<00:00,  5.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(prior_sample:) Sampling done. Check fails for 4.76% of the prior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "p0 = mod.prior_sampler(40, verbose=True) # rule of thumb: number_of_parameters times 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter draws are saved in the object `p0` as a numpy array in order to later pass them to our main sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_meta:]    Metadata saved as '/tmp/output/rank_tutorial_meta'\n"
     ]
    }
   ],
   "source": [
    "mod.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mod.save()` saved the meta data of our model in the directory which we specified earlier in `mod.path`. This information is stored as an `.npz` file so that it is avialable even in the event of a crash and can be loaded anytime using `numpy.load()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For posterior sampling using `mcmc` we have the option to set different \"moves\", i.e. coordinate updating algorithms for the walkers. As a wrapper for a lot of `emcee` functionality,  `mcmc` can work with many different \"moves\" - for a list and implementation details please consult the `emcee` documentation. \n",
    "\n",
    "The default is however to use the DIME MCMC sampler from [this paper](https://gregorboehl.com/live/dime_mcmc_boehl.pdf), which is very efficient for burn-in and robust to multimodal distributions. The sampler is provided by the [emcwrap package](https://github.com/gboehl/emcwrap). This is also the default sampler for pydsge, so the below is actually not necessary and the ``moves`` keyword can just be omited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "from emcwrap import DIMEMove\n",
    "moves = DIMEMove(aimh_prob=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the initial states derived above to conduct our full Bayesian estimation using `mcmc`. Note that, instead of using the specified initial ensemble, `mcmc` can identify previous runs or estimations, or the initial values of the \"prior\" section in the `*.yaml` can be used. \n",
    "\n",
    "The default number of sampling steps is 3000, which is parallelized by default. With `tune` we can determine the size of the Markov Chain we wish to retain to represent the posterior, i.e. after burn-in. This is not to be confused this with the updating frequency, which only affects the number of summary statements `pydsge`reports during the estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the option `lprob_seed` the user can choose how to set the random seed of the likelihood evaluation - here we use the seed specified in `prep_estim`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc:]         HDF backend at /tmp/output/rank_tutorial_sampler.h5 already exists. Deleting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:-124.691(3e+01)/10% | -2e+01]:  13%|█▎        | 51/400 [03:12<20:09,  3.47s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 50 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.606  0.067  0.625  0.493   0.697   \n",
      "sigma             normal     1.500  0.375  1.108  0.537  1.446  0.246   1.864   \n",
      "phi_pi            normal     1.500  0.250  1.821  0.640  1.521  0.993   2.891   \n",
      "phi_y             normal     0.125  0.050  0.135  0.156  0.134 -0.129   0.380   \n",
      "rho_u               beta     0.500  0.200  0.725  0.072  0.610  0.610   0.835   \n",
      "rho_r               beta     0.500  0.200  0.636  0.100  0.663  0.517   0.803   \n",
      "rho_z               beta     0.500  0.200  0.420  0.292  0.576  0.017   0.847   \n",
      "rho                 beta     0.750  0.100  0.724  0.137  0.686  0.520   0.926   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.757  0.274  1.067  0.300   1.139   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.666  0.459  1.118  0.086   1.221   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  1.063  0.316  1.053  0.563   1.505   \n",
      "\n",
      "        error  \n",
      "theta   0.006  \n",
      "sigma   0.042  \n",
      "phi_pi  0.061  \n",
      "phi_y   0.016  \n",
      "rho_u   0.007  \n",
      "rho_r   0.010  \n",
      "rho_z   0.029  \n",
      "rho     0.014  \n",
      "sig_u   0.015  \n",
      "sig_r   0.039  \n",
      "sig_z   0.030  \n",
      "Mean acceptance fraction:        0.249\n",
      "Autocorrelation times are between 2.64 and 3.56.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:-59.472(2e+01)/ 5% | -5e-01]:  25%|██▌       | 101/400 [06:17<20:01,  4.02s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 100 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.558  0.166  0.584  0.314   0.814   \n",
      "sigma             normal     1.500  0.375  1.135  0.464  1.420  0.368   1.833   \n",
      "phi_pi            normal     1.500  0.250  2.668  0.929  2.983  1.024   3.758   \n",
      "phi_y             normal     0.125  0.050  0.077  0.197 -0.138 -0.212   0.379   \n",
      "rho_u               beta     0.500  0.200  0.771  0.078  0.747  0.639   0.873   \n",
      "rho_r               beta     0.500  0.200  0.570  0.161  0.556  0.322   0.822   \n",
      "rho_z               beta     0.500  0.200  0.663  0.414  0.936  0.016   0.987   \n",
      "rho                 beta     0.750  0.100  0.706  0.165  0.544  0.432   0.917   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.384  0.148  0.515  0.134   0.573   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.324  0.221  0.673  0.063   0.595   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.888  0.345  0.727  0.378   1.505   \n",
      "\n",
      "        error  \n",
      "theta   0.017  \n",
      "sigma   0.036  \n",
      "phi_pi  0.097  \n",
      "phi_y   0.020  \n",
      "rho_u   0.008  \n",
      "rho_r   0.017  \n",
      "rho_z   0.042  \n",
      "rho     0.018  \n",
      "sig_u   0.014  \n",
      "sig_r   0.023  \n",
      "sig_z   0.028  \n",
      "Mean acceptance fraction:        0.208\n",
      "Autocorrelation times are between 4.78 and 7.75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:-18.338(9e+00)/12% | -8e-02]:  38%|███▊      | 151/400 [09:46<17:47,  4.29s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 150 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.710  0.183  0.947  0.480   0.981   \n",
      "sigma             normal     1.500  0.375  1.735  0.579  1.702  0.967   2.833   \n",
      "phi_pi            normal     1.500  0.250  2.743  0.895  0.561  1.228   4.030   \n",
      "phi_y             normal     0.125  0.050  0.088  0.153  0.531 -0.113   0.360   \n",
      "rho_u               beta     0.500  0.200  0.897  0.047  0.851  0.837   0.970   \n",
      "rho_r               beta     0.500  0.200  0.575  0.196  0.878  0.274   0.871   \n",
      "rho_z               beta     0.500  0.200  0.766  0.374  0.002  0.018   0.999   \n",
      "rho                 beta     0.750  0.100  0.837  0.077  0.814  0.727   0.934   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.252  0.120  0.649  0.095   0.395   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.169  0.088  0.107  0.061   0.269   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.406  0.374  0.424  0.047   0.842   \n",
      "\n",
      "        error  \n",
      "theta   0.020  \n",
      "sigma   0.064  \n",
      "phi_pi  0.109  \n",
      "phi_y   0.019  \n",
      "rho_u   0.004  \n",
      "rho_r   0.023  \n",
      "rho_z   0.046  \n",
      "rho     0.009  \n",
      "sig_u   0.013  \n",
      "sig_r   0.010  \n",
      "sig_z   0.040  \n",
      "Mean acceptance fraction:        0.176\n",
      "Autocorrelation times are between 7.65 and 11.38.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:-18.338(9e+00)/ 0% | -9e-02]:  38%|███▊      | 152/400 [09:50<17:35,  4.26s/sample(s)]/home/gboehl/github/emcwrap/emcwrap/moves.py:91: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(sum(self.accepted)) - np.log(nchain)\n",
      "[ll/MAF:  6.086(9e+00)/ 5% | -9e-02]:  50%|█████     | 201/400 [13:21<14:23,  4.34s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 200 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.804  0.134  0.918  0.613   0.984   \n",
      "sigma             normal     1.500  0.375  2.131  0.602  0.988  1.256   3.154   \n",
      "phi_pi            normal     1.500  0.250  2.450  0.649  2.311  1.345   3.366   \n",
      "phi_y             normal     0.125  0.050  0.153  0.102  0.139 -0.013   0.275   \n",
      "rho_u               beta     0.500  0.200  0.935  0.020  0.938  0.904   0.962   \n",
      "rho_r               beta     0.500  0.200  0.592  0.176  0.451  0.353   0.857   \n",
      "rho_z               beta     0.500  0.200  0.788  0.345  0.458  0.052   0.999   \n",
      "rho                 beta     0.750  0.100  0.855  0.049  0.896  0.786   0.927   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.238  0.094  0.201  0.108   0.385   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.119  0.041  0.102  0.069   0.176   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.190  0.163  0.151  0.021   0.370   \n",
      "\n",
      "        error  \n",
      "theta   0.017  \n",
      "sigma   0.067  \n",
      "phi_pi  0.082  \n",
      "phi_y   0.013  \n",
      "rho_u   0.002  \n",
      "rho_r   0.022  \n",
      "rho_z   0.045  \n",
      "rho     0.006  \n",
      "sig_u   0.011  \n",
      "sig_r   0.005  \n",
      "sig_z   0.016  \n",
      "Mean acceptance fraction:         0.15\n",
      "Autocorrelation times are between 9.8 and 15.2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:  8.158(9e+00)/ 0% | -3e-01]:  57%|█████▋    | 227/400 [15:11<12:18,  4.27s/sample(s)]/home/gboehl/github/emcwrap/emcwrap/moves.py:91: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(sum(self.accepted)) - np.log(nchain)\n",
      "[ll/MAF: 10.731(9e+00)/ 5% | -1e-01]:  63%|██████▎   | 251/400 [16:53<10:25,  4.20s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 250 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.792  0.115  0.822  0.648   0.981   \n",
      "sigma             normal     1.500  0.375  2.286  0.540  2.554  1.469   3.195   \n",
      "phi_pi            normal     1.500  0.250  2.304  0.483  2.579  1.270   2.825   \n",
      "phi_y             normal     0.125  0.050  0.144  0.087  0.134  0.020   0.270   \n",
      "rho_u               beta     0.500  0.200  0.944  0.020  0.959  0.909   0.969   \n",
      "rho_r               beta     0.500  0.200  0.557  0.158  0.644  0.287   0.796   \n",
      "rho_z               beta     0.500  0.200  0.842  0.318  0.981  0.169   1.000   \n",
      "rho                 beta     0.750  0.100  0.839  0.050  0.810  0.783   0.926   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.212  0.108  0.168  0.098   0.431   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.106  0.025  0.117  0.067   0.138   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.174  0.098  0.112  0.035   0.291   \n",
      "\n",
      "        error  \n",
      "theta   0.015  \n",
      "sigma   0.062  \n",
      "phi_pi  0.063  \n",
      "phi_y   0.012  \n",
      "rho_u   0.003  \n",
      "rho_r   0.019  \n",
      "rho_z   0.043  \n",
      "rho     0.006  \n",
      "sig_u   0.014  \n",
      "sig_r   0.003  \n",
      "sig_z   0.012  \n",
      "Mean acceptance fraction:        0.133\n",
      "Autocorrelation times are between 11.27 and 18.85.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF: 10.731(9e+00)/ 0% | -5e-02]:  63%|██████▎   | 252/400 [16:57<10:19,  4.19s/sample(s)]/home/gboehl/github/emcwrap/emcwrap/moves.py:91: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(sum(self.accepted)) - np.log(nchain)\n",
      "[ll/MAF: 15.635(5e+00)/10% | -7e-02]:  75%|███████▌  | 301/400 [20:21<06:52,  4.17s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 300 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.787  0.081  0.973  0.668   0.954   \n",
      "sigma             normal     1.500  0.375  2.319  0.358  2.110  1.831   2.957   \n",
      "phi_pi            normal     1.500  0.250  2.291  0.343  1.196  1.944   2.802   \n",
      "phi_y             normal     0.125  0.050  0.130  0.060  0.219  0.044   0.221   \n",
      "rho_u               beta     0.500  0.200  0.951  0.015  0.957  0.928   0.971   \n",
      "rho_r               beta     0.500  0.200  0.532  0.117  0.709  0.361   0.727   \n",
      "rho_z               beta     0.500  0.200  0.920  0.228  0.394  0.658   0.999   \n",
      "rho                 beta     0.750  0.100  0.829  0.040  0.916  0.775   0.896   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.176  0.075  0.200  0.101   0.260   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.101  0.017  0.068  0.079   0.133   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.152  0.075  0.131  0.044   0.254   \n",
      "\n",
      "        error  \n",
      "theta   0.010  \n",
      "sigma   0.041  \n",
      "phi_pi  0.042  \n",
      "phi_y   0.007  \n",
      "rho_u   0.002  \n",
      "rho_r   0.014  \n",
      "rho_z   0.030  \n",
      "rho     0.004  \n",
      "sig_u   0.010  \n",
      "sig_r   0.002  \n",
      "sig_z   0.008  \n",
      "Mean acceptance fraction:        0.129\n",
      "Autocorrelation times are between 13.0 and 22.48.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF: 15.212(4e+00)/ 0% | -4e-02]:  84%|████████▍ | 337/400 [22:50<04:18,  4.10s/sample(s)]/home/gboehl/github/emcwrap/emcwrap/moves.py:91: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(sum(self.accepted)) - np.log(nchain)\n",
      "[ll/MAF: 15.067(3e+00)/15% | -2e-02]:  88%|████████▊ | 351/400 [23:47<03:22,  4.13s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(mcmc:) Summary from last 50 of 350 iterations (RANK, estimation tutorial):\n",
      "            distribution  pst_mean  sd/df   mean     sd   mode  hpd_5  hpd_95  \\\n",
      "theta               beta     0.500  0.100  0.788  0.051  0.773  0.724   0.863   \n",
      "sigma             normal     1.500  0.375  2.233  0.287  1.784  1.772   2.633   \n",
      "phi_pi            normal     1.500  0.250  2.301  0.277  2.489  1.982   2.716   \n",
      "phi_y             normal     0.125  0.050  0.120  0.040  0.080  0.041   0.162   \n",
      "rho_u               beta     0.500  0.200  0.956  0.009  0.942  0.943   0.970   \n",
      "rho_r               beta     0.500  0.200  0.540  0.089  0.549  0.421   0.725   \n",
      "rho_z               beta     0.500  0.200  0.977  0.113  0.998  0.990   0.999   \n",
      "rho                 beta     0.750  0.100  0.820  0.037  0.824  0.764   0.863   \n",
      "sig_u   inv_gamma_dynare     0.100  2.000  0.154  0.035  0.187  0.097   0.196   \n",
      "sig_r   inv_gamma_dynare     0.100  2.000  0.100  0.013  0.092  0.077   0.119   \n",
      "sig_z   inv_gamma_dynare     0.100  2.000  0.123  0.049  0.121  0.048   0.203   \n",
      "\n",
      "        error  \n",
      "theta   0.006  \n",
      "sigma   0.034  \n",
      "phi_pi  0.035  \n",
      "phi_y   0.005  \n",
      "rho_u   0.001  \n",
      "rho_r   0.011  \n",
      "rho_z   0.015  \n",
      "rho     0.005  \n",
      "sig_u   0.004  \n",
      "sig_r   0.002  \n",
      "sig_z   0.006  \n",
      "Mean acceptance fraction:        0.127\n",
      "Autocorrelation times are between 14.8 and 26.49.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF: 15.209(2e+00)/10% | -1e-02]: 100%|██████████| 400/400 [27:09<00:00,  4.07s/sample(s)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_meta:]    Metadata saved as '/tmp/output/rank_tutorial_meta'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mod.mcmc(p0,\n",
    "         moves=moves,\n",
    "         nsteps=400,\n",
    "         tune=100,\n",
    "         update_freq=50,\n",
    "         ) # this may take some time. Better run on a machine with MANY cores...\n",
    "mod.save() # be sure to save the internal state!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. On my 8 core machine this took 27 Minutes. \n",
    "\n",
    "So where are our estimates? Our (hopefully) converged MCMC samples are currently stored in the file named `rank_tutorial_sampler.h5` created by `mcmc` which is stored in the `output_path`. \n",
    "\n",
    "You can load and use this data using the methods introduced in the [*processing estimation results tutorial*](https://pydsge.readthedocs.io/en/latest/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the tutorial: Cleaning the temporary directory\n",
    "shutil.rmtree(output_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d226595e2f076559e618d0a9d30d224ac27d056d5cb4864945e1f27051c61083"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
