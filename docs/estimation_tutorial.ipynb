{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimation Tutorial\n",
    "\n",
    "In this section, we dive into the topic of model estimation using **pydsge**. \n",
    "\n",
    "Let us, just for the sake of this tutorial, set up a temporary directory structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the tutorial: Setting up example structure\n",
    "import tempfile\n",
    "import os\n",
    "import shutil # For clean-up of temporary directory\n",
    "from pathlib import Path # For Windows/Unix compatibility\n",
    "\n",
    "# Temporary output folder\n",
    "output_path = Path(tempfile.gettempdir(), 'output')\n",
    "if not os.path.isdir(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and loading the model\n",
    "\n",
    "Let us first load the relevant packages. Besides the DSGE class we already know from [*getting started*](https://pydsge.readthedocs.io/en/latest/getting_started.html), we also want to import the `emcee` package. This will allow us to later specify the desired updating algorithms for sampling from the posterior distribution - we explain this in more detail below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import emcee # For specifying updating moves\n",
    "\n",
    "from pydsge import DSGE, example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we continue to use the example provided in `pydsge`. Like before, we specify the file paths of the model and the data. Please feel free to check-out both files, but from the previous tutorial you might remember that we're dealing with a five equations New Keynesian model and US quarterly data from 1995 to 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_file, data_file = example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again parse the model and load-in the data. What is important is that we also specify a location where the (intermediate) output is stored. Here we assign the output folder, as discussed at the beginning. Note also that we can name the model and write a short description, which is very useful when working with several models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the model\n",
    "mod = DSGE.read(yaml_file)  \n",
    "\n",
    "# Give it a name\n",
    "mod.name = 'Rank_tutorial'\n",
    "mod.description = 'RANK, estimation tutorial'\n",
    "\n",
    "# Storage location for output\n",
    "mod.path = output_path\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(data_file, parse_dates=['date'], index_col=['date'])\n",
    "df.index.freq = 'Q' # let pandas know that this is quartely data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that since the Great Recession, the Federal Funds Rate has been below the ZLB. That is why, like in [*getting started*](https://pydsge.readthedocs.io/en/latest/getting_started.html), we adjust the observed interest rate, so that the data is \"within reach\" of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>Infl</th>\n",
       "      <th>FFR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1998-03-31</th>\n",
       "      <td>0.77834</td>\n",
       "      <td>0.14386</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-06-30</th>\n",
       "      <td>0.69635</td>\n",
       "      <td>0.22873</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-09-30</th>\n",
       "      <td>1.03077</td>\n",
       "      <td>0.36109</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998-12-31</th>\n",
       "      <td>1.37921</td>\n",
       "      <td>0.26145</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999-03-31</th>\n",
       "      <td>0.54307</td>\n",
       "      <td>0.37393</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-31</th>\n",
       "      <td>0.41475</td>\n",
       "      <td>0.49969</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-30</th>\n",
       "      <td>0.54594</td>\n",
       "      <td>0.25245</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-09-30</th>\n",
       "      <td>0.54391</td>\n",
       "      <td>0.51972</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>0.48458</td>\n",
       "      <td>0.57830</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-31</th>\n",
       "      <td>0.15170</td>\n",
       "      <td>0.48097</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GDP     Infl   FFR\n",
       "date                              \n",
       "1998-03-31  0.77834  0.14386  1.38\n",
       "1998-06-30  0.69635  0.22873  1.38\n",
       "1998-09-30  1.03077  0.36109  1.38\n",
       "1998-12-31  1.37921  0.26145  1.22\n",
       "1999-03-31  0.54307  0.37393  1.18\n",
       "...             ...      ...   ...\n",
       "2017-03-31  0.41475  0.49969  0.18\n",
       "2017-06-30  0.54594  0.25245  0.24\n",
       "2017-09-30  0.54391  0.51972  0.29\n",
       "2017-12-31  0.48458  0.57830  0.30\n",
       "2018-03-31  0.15170  0.48097  0.36\n",
       "\n",
       "[81 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adjust elb\n",
    "zlb = mod.get_par('elb_level')\n",
    "rate = df['FFR']\n",
    "df['FFR'] = np.maximum(rate,zlb)\n",
    "\n",
    "mod.load_data(df, start='1998Q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the packages and loading the data, we still need to tell pydsge how to carry out the estimation of our model. The \"prep_estim\" method can be used to accomplish this. It can be called without any arguments and sets-up a non-linear model by default. However, not all defaults are always a good good choice, and to showcase some of this functionality, we decide to specify several arguments here.\n",
    "\n",
    "To perform the estimation, `pydsge` uses a Transposed-Ensemble Kalman Filter (TEnKF). For general information on its implementation, see the [EconSieve documentation](https://econsieve.readthedocs.io/en/latest/) , and for more details on running the filter in `pydsge` check-out the [*getting started tutorial*](https://pydsge.readthedocs.io/en/latest/getting_started.html). Again,  the default filter is non-linear, but we can opt for a linear one by setting the argument `linear` to `True`. To choose a custom number of ensemble members for the TEnKF, set `N` to a particular number (default is 300, for e.g. a medium scale model 400-500 is a good choice). We can also set a specific random seed with the argument `seed` (the default seed is `0`). To get additional information on the estimation process, we can set  `verbose` to `True`. Conveniently, this information includes an overview of the parameters’ distribution, their means and standard deviations. Finally, if we already specified the covariance matrix of the measurement errors or want to reuse a previous result, we can load it into the `prep_estim` method by setting `Load.R` to `True`. \n",
    "\n",
    "If you run into problems you can turn parallelization off by setting `debug=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[estimation:]   Model operational. 12 states, 3 observables, 3 shocks, 81 data points.\n",
      "Adding parameters to the prior distribution...\n",
      "  parameter theta as beta (0.5, 0.1). Init @ 0.7813, with bounds (0.2, 0.95)...\n",
      "  parameter sigma as normal (1.5, 0.375). Init @ 1.2312, with bounds (0.25, 3)...\n",
      "  parameter phi_pi as normal (1.5, 0.25). Init @ 1.7985, with bounds (1.0, 3)...\n",
      "  parameter phi_y as normal (0.125, 0.05). Init @ 0.0893, with bounds (0.001, 0.5)...\n",
      "  parameter rho_u as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)...\n",
      "  parameter rho_r as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)...\n",
      "  parameter rho_z as beta (0.5, 0.2). Init @ 0.7, with bounds (0.01, 0.9999)...\n",
      "  parameter rho as beta (0.75, 0.1). Init @ 0.8, with bounds (0.5, 0.975)...\n",
      "  parameter sig_u as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.025, 5)...\n",
      "  parameter sig_r as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.01, 3)...\n",
      "  parameter sig_z as inv_gamma_dynare (0.1, 2). Init @ 0.5, with bounds (0.01, 3)...\n",
      "[estimation:]   11 priors detected. Adding parameters to the prior distribution.\n"
     ]
    }
   ],
   "source": [
    "mod.prep_estim(N=350, seed=0, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the filtering tutorial, we set the covariance of measurement errors to correspond to the variances of the data. Additionally, we adjust the measurement errors of the Federal Funds rate since it is perfectly observable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.filter.R = mod.create_obs_cov(1e-1)\n",
    "ind = mod.observables.index('FFR')\n",
    "mod.filter.R[ind,ind] /= 1e1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets turn to the actual estimation. For a variety of pretty good reasons, `pdygse` uses *Ensemble Markov Chain Monte Carlo* (Ensemble-MCMC) integration to sample from the posterior distribution. For further information on Ensemble-MCMC, please refer to the `emcee` [website](https://emcee.readthedocs.io/en/stable/) and the additional resources provided there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first require an initial ensemble, which is provided by `tmcmc`. `tmcmc` is a very sophisticated function with many options, but right now, all we are interested in is to obtain a sample that represents the prior distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:07<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[prior_sample:] Sampling done. 3.85% of the prior is either indetermined or explosive.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0temp(s) [00:00, ?temp(s)/s]\n"
     ]
    }
   ],
   "source": [
    "p0 = mod.tmcmc(200) # 200 is a bit of an overkill for this small model... rule of thumb: number_of_parameters times 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter draws are saved in the object `p0` as a numpy array in order to later pass them to our main sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save_meta:]    Metadata saved as '/tmp/output/Rank_tutorial_meta'\n"
     ]
    }
   ],
   "source": [
    "mod.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mod.save()` saved the meta data of our model in the directory which we specified earlier in `mod.path`. This information is stored as an `.npz` file so that it is avialable even in the event of a crash and can be loaded anytime using `numpy.load()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For posterior sampling using `mcmc` we have the option to set different \"moves\", i.e. coordinate updating algorithms for the walkers. As a wrapper for a lot of `emcee` functionality,  `mcmc` can work with many different \"moves\" - for a list and implementation details please consult the `emcee` documentation. For using them here, specify them as a list of tuples, containing the type of move and its \"weight\". If no move is specified, `StretchMove` is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "moves = [(emcee.moves.DEMove(), 0.8), \n",
    "         (emcee.moves.DESnookerMove(), 0.2),]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the initial states derived above to conduct our full Bayesian estimation using `mcmc`. Note that, instead of using the specified initial ensemble, `mcmc` can identify previous runs or estimations, or the initial values of the \"prior\" section in the `*.yaml` can be used. \n",
    "\n",
    "The default number of sampling steps is 3000, which is parallelized by default. With `tune` we can determine the size of the Markov Chain we wish to retain to represent the posterior, i.e. after burn-in. This is not to be confused this with the updating frequency, which only affects the number of summary statements `pydsge`reports during the estimation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the option `lprob_seed` the user can choose how to set the random seed of the likelihood evaluation - here we use the seed specified in `prep_estim`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc:]         HDF backend at /tmp/output/Rank_tutorial_sampler.h5 already exists. Deleting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ll/MAF:-82.148(3e+02)/22%]:   1%|          | 25/3000 [05:04<9:23:55, 11.37s/sample(s)]"
     ]
    }
   ],
   "source": [
    "mod.mcmc(p0,\n",
    "         moves=moves,\n",
    "         nsteps=3000,\n",
    "         tune=500,\n",
    "         update_freq=500,\n",
    "         lprob_seed='set'\n",
    "         ) # this may take some time...\n",
    "mod.save() # be sure to save the internal state!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. So where are our estimates? Our (hopefully) converged MCMC samples are currently stored in the `rank_test_sampler.h5` file created by `mcmc`. \n",
    "\n",
    "You can load and use this data using the methods introduced in the [*processing estimation results tutorial*](https://pydsge.readthedocs.io/en/latest/getting_started.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just for the tutorial: Cleaning the temporary directory\n",
    "shutil.rmtree(output_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d226595e2f076559e618d0a9d30d224ac27d056d5cb4864945e1f27051c61083"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
